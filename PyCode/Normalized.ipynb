{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cc25b82-99c8-4ad9-bcb3-ded75be0edb3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# import glmnet_python\n",
    "# from glmnet_python import glmnet\n",
    "# from glmnet_python import glmnetPredict\n",
    "# from glmnet_python import glmnetPlot\n",
    "# from glmnet_python import cvglmnet\n",
    "# from glmnet_python import cvglmnetPredict\n",
    "# from glmnet_python import cvglmnetPlot\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import codecs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pingouin as pg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5ded2e-9dd1-4646-8da6-b0c3124f2319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES TO ADJUST\n",
    "# 'Mugs', 'Plates', 'Geometric', 'Cutlery', 'Ball'\n",
    "family_to_select = 'Ball'\n",
    "target = 'Middle Abd'\n",
    "num_bins = 20\n",
    "cv = 3\n",
    "# C_par [0.2, 0.5, 1, 1.25, 1.5]\n",
    "C_par = 0.2\n",
    "l1vsl2 = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73b464b5-7926-46fc-9d57-dd91e9e90824",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "obj_fam = dict(\n",
    "    CeramicMug = 'Mugs',\n",
    "    Glass = 'Mugs',\n",
    "    MetalMug = 'Mugs',\n",
    "    CeramicPlate = 'Plates',\n",
    "    MetalPlate = 'Plates',\n",
    "    PlasticPlate = 'Plates',\n",
    "    Cube = 'Geometric',\n",
    "    Cylinder ='Geometric',\n",
    "    Triangle ='Geometric',\n",
    "    Fork = 'Cutlery',\n",
    "    Knife ='Cutlery',\n",
    "    Spoon ='Cutlery',\n",
    "    PingPongBall = 'Ball',\n",
    "    SquashBall='Ball',\n",
    "    TennisBall='Ball'\n",
    ")\n",
    "\n",
    "kin_labels = [\"Thumb Rotate\", \"Thumb MPJ\", \"Thumb IJ\", \"Index MPJ\", \"Index PIJ\", \"Middle MPJ\", \"Middle PIJ\", \"Ring MPJ\", \"Ring PIJ\", \"Pinkie MPJ\", \"Pinkie PIJ\", \"Palm Arch\", \"Wrist Pitch\", \"Wrist Yaw\", \"Index Abd\", \"Pinkie Abd\", \"Ring Abd\", \"Middle Abd\", \"Thumb Abd\"]\n",
    "emg_labels = ['emg' + str(i) for i in range(0,64)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8864994-42ef-4341-a609-401fac9cc03b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# READING FILES AND CREATING DATASET\n",
    "file_kin = \"./PyData/filtered_data.json\"\n",
    "file_eps = \"./PyData/ep_labels.json\"\n",
    "file_task = \"./PyData/task_labels.json\"\n",
    "file_emg = \"./PyData/emg_data.json\"\n",
    "\n",
    "with open(file_kin, \"r\") as f:\n",
    "    kin_data = json.load(f)  # data[subjects][trials][joints]\n",
    "\n",
    "with open(file_eps, \"r\") as g:\n",
    "    eps = json.load(g)  # eps[subjects][trials]\n",
    "\n",
    "with open(file_task, \"r\") as h:\n",
    "    task = json.load(h)  # task[subjects][trials]\n",
    "\n",
    "with open(file_emg, \"r\") as f:\n",
    "    emg_data = json.load(f)  # data[subjects][trials][sensors]\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f190949-8299-4c55-9f7d-357d03b2dec8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VECTORIZING DATA\n",
    "\n",
    "vectorized_task = [x for sublist in task for x in sublist]  # Vectorization of tasks\n",
    "vectorized_eps = [x for sublist in eps for x in sublist]  # Vectorization of eps\n",
    "vectorized_kin = [x for sublist in kin_data for x in sublist]  # Vectorization of trials\n",
    "vectorized_kin = np.array(vectorized_kin, dtype=float) # Conversion to float to replace 'None' with 'NaN'\n",
    "vectorized_emg = [x for sublist in emg_data for x in sublist]  # Vectorization of trials\n",
    "vectorized_emg = np.array(vectorized_emg, dtype=float) # Conversion to float to replace 'None' with 'NaN'\n",
    "given_object = [x.split(\"_\")[0] for x in vectorized_task]  # Vectorized given objects\n",
    "ask_object = [x.split(\"_\")[1] for x in vectorized_task]  # Vectorized asked objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c632103-bcf4-479b-af0e-789eec1c655b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CREATE PANDAS DATAFRAME AND GENERATE TRIAL AND EP INDEX\n",
    "\n",
    "aux = np.concatenate([vectorized_kin, vectorized_emg], axis=1)\n",
    "labs = np.concatenate([kin_labels, emg_labels])\n",
    "\n",
    "new_df = pd.DataFrame(aux, columns=labs)\n",
    "new_df['EPs'] = vectorized_eps\n",
    "new_df['Task'] = vectorized_task\n",
    "new_df['Given'] = given_object\n",
    "new_df['Asked'] = ask_object\n",
    "new_df['Family'] = [obj_fam[x] for x in given_object]\n",
    "\n",
    "tr = 0\n",
    "trial = np.zeros((len(new_df['Task']),), dtype=int)\n",
    "trial_list = list()\n",
    "objects_list = list()\n",
    "trial_list.append(tr)\n",
    "objects_list.append(given_object[0])\n",
    "\n",
    "for i in range(1,len(new_df['Task'])):\n",
    "    if vectorized_task[i] != vectorized_task[i-1]:\n",
    "        tr += 1\n",
    "        trial_list.append(tr)\n",
    "        objects_list.append(given_object[i])\n",
    "    trial[i] = tr\n",
    "        \n",
    "new_df['Trial number'] = trial        \n",
    "new_df['Trial number'] = new_df['Trial number'].astype(str)               \n",
    "\n",
    "ep = 0\n",
    "eps = np.zeros((len(new_df['EPs']),), dtype=int)\n",
    "\n",
    "for j in range(1,len(new_df['EPs'])):\n",
    "    if vectorized_task[j] != vectorized_task[j-1]: # EP to 0 if we change trial\n",
    "        ep = 0\n",
    "    elif vectorized_eps[j] != vectorized_eps[j-1]:\n",
    "        ep += 1\n",
    "    eps[j] = ep \n",
    "        \n",
    "new_df['EP number'] = eps        \n",
    "new_df['EP number'] = new_df['EP number'].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e8a3553-e2c0-4a3c-8ea7-6e1417a761fa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SELECT DATAPOINTS BY FAMILY\n",
    "\n",
    "sel_df = new_df.loc[new_df['Family'] == family_to_select]\n",
    "\n",
    "selected_trials = np.unique(sel_df['Trial number'])\n",
    "selected_objects = [np.unique(sel_df['Given'].loc[sel_df['Trial number'] == tri]) for tri in selected_trials]\n",
    "\n",
    "selected = pd.DataFrame(list(zip(selected_trials,selected_objects)), columns=['Trial', 'Object'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "084f1d2d-2f22-4938-839e-68472b3dd9a2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2893/3719258072.py:56: RuntimeWarning: Mean of empty slice\n",
      "  ep_mean_train = [np.nanmean(x, axis=0) for x in split_ep_train] # (number of bins) x (number of sensors (kin + emg = 83))\n",
      "/tmp/ipykernel_2893/3719258072.py:78: RuntimeWarning: Mean of empty slice\n",
      "  ep_mean_test = [np.nanmean(x, axis=0) for x in split_ep_test] # (number of bins) x (number of sensors (kin + emg = 83))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits:  46  out of  69 .  66.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2893/3719258072.py:56: RuntimeWarning: Mean of empty slice\n",
      "  ep_mean_train = [np.nanmean(x, axis=0) for x in split_ep_train] # (number of bins) x (number of sensors (kin + emg = 83))\n",
      "/tmp/ipykernel_2893/3719258072.py:78: RuntimeWarning: Mean of empty slice\n",
      "  ep_mean_test = [np.nanmean(x, axis=0) for x in split_ep_test] # (number of bins) x (number of sensors (kin + emg = 83))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits:  23  out of  55 .  41.82 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2893/3719258072.py:56: RuntimeWarning: Mean of empty slice\n",
      "  ep_mean_train = [np.nanmean(x, axis=0) for x in split_ep_train] # (number of bins) x (number of sensors (kin + emg = 83))\n",
      "/tmp/ipykernel_2893/3719258072.py:78: RuntimeWarning: Mean of empty slice\n",
      "  ep_mean_test = [np.nanmean(x, axis=0) for x in split_ep_test] # (number of bins) x (number of sensors (kin + emg = 83))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits:  36  out of  70 .  51.43 %\n",
      "|| FAMILY:  Ball  || Mean accuracy after  3  folds with  20  bins per EP:  53.31  % ||\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "# K-FOLD, Z-SCORE, BIN CREATION, CLASSIFICATION AND STATISTICAL TEST ¿¿¿???\n",
    "\n",
    "# STRATIFIED K-FOLD CROSS VALIDATION\n",
    "skf = StratifiedKFold(n_splits=cv)\n",
    "\n",
    "total_acc = list() # TOTAL ACCURACY\n",
    "\n",
    "# NOPE: vectorize task number\n",
    "for train, test in skf.split(selected['Trial'].astype(int), selected['Object'].astype(str)): \n",
    "    \n",
    "    # TRAIN/TEST SPLIT\n",
    "    trials_train = selected.iloc[train]['Trial'].array\n",
    "    train_df = sel_df.loc[sel_df['Trial number'].isin(trials_train)]\n",
    "    \n",
    "    trials_test = selected.iloc[test]['Trial'].array\n",
    "    test_df = sel_df.loc[sel_df['Trial number'].isin(trials_test)]\n",
    "    \n",
    "    # Z-SCORE NORMALIZATION, ADD MISSING (no numerical) COLUMNS AND REARRANGE DATAFRAME (to fit original order)\n",
    "    train_z = train_df[train_df.select_dtypes(include=[np.number]).columns].apply(stats.zscore,nan_policy='omit')\n",
    "    train_z['EPs'] = train_df['EPs']\n",
    "    train_z['Task'] = train_df['Task']\n",
    "    train_z['Given'] = train_df['Given']\n",
    "    train_z['Asked'] = train_df['Asked']\n",
    "    train_z['Family'] = train_df['Family']\n",
    "    train_z['Trial number'] = train_df['Trial number']\n",
    "    train_z['EP number'] = train_df['EP number']\n",
    "    train_z = train_z.reindex(columns=train_df.columns)\n",
    "    \n",
    "    test_z = test_df[test_df.select_dtypes(include=[np.number]).columns].apply(stats.zscore,nan_policy='omit')\n",
    "    test_z['EPs'] = test_df['EPs']\n",
    "    test_z['Task'] = test_df['Task']\n",
    "    test_z['Given'] = test_df['Given']\n",
    "    test_z['Asked'] = test_df['Asked']\n",
    "    test_z['Family'] = test_df['Family']\n",
    "    test_z['Trial number'] = test_df['Trial number']\n",
    "    test_z['EP number'] = test_df['EP number']\n",
    "    test_z = test_z.reindex(columns=test_df.columns)\n",
    "    \n",
    "    # DIVIDE IN BINS AND COMPUTE MEAN\n",
    "    train_list = list() # One row per EP\n",
    "    train_lab = list() # Labels \n",
    "    \n",
    "    for it1 in trials_train: # Loop over trials\n",
    "        \n",
    "        each_train_trial = train_z.loc[train_z['Trial number'] == it1] \n",
    "        eps_in_trial = np.unique(each_train_trial['EP number'])\n",
    "\n",
    "        for it2 in eps_in_trial: # Loop over EPs in each trial\n",
    "\n",
    "            each_ep_train = each_train_trial.loc[each_train_trial['EP number'] == it2]\n",
    "\n",
    "            ep_to_array_train = each_ep_train[each_ep_train.select_dtypes(include=[np.number]).columns]\n",
    "\n",
    "            split_ep_train = np.array_split(ep_to_array_train, num_bins) # (timepoints per EP) x (number of sensors (kin + emg = 83))\n",
    "            \n",
    "            ep_mean_train = [np.nanmean(x, axis=0) for x in split_ep_train] # (number of bins) x (number of sensors (kin + emg = 83))\n",
    "\n",
    "            flat_ep_train = [item for sublist in ep_mean_train for item in sublist] # UNIDIMENSIONAL ARRAY: 1 x (number of bins x number of sensors)\n",
    "            train_list.append(flat_ep_train)\n",
    "            train_lab.append(each_train_trial['Given'].iloc[0])\n",
    "    \n",
    "    test_list = list() # One row per EP\n",
    "    test_lab = list() # Labels \n",
    "    \n",
    "    for ite1 in trials_test: # Loop over trials\n",
    "        \n",
    "        each_test_trial = test_z.loc[test_z['Trial number'] == ite1] \n",
    "        eps_in_test = np.unique(each_test_trial['EP number'])\n",
    "\n",
    "        for ite2 in eps_in_test: # Loop over EPs in each trial\n",
    "\n",
    "            each_ep_test = each_test_trial.loc[each_test_trial['EP number'] == ite2]\n",
    "\n",
    "            ep_to_array_test = each_ep_test[each_ep_test.select_dtypes(include=[np.number]).columns]\n",
    "\n",
    "            split_ep_test = np.array_split(ep_to_array_test, num_bins) # (timepoints per EP) x (number of sensors (kin + emg = 83))\n",
    "            \n",
    "            ep_mean_test = [np.nanmean(x, axis=0) for x in split_ep_test] # (number of bins) x (number of sensors (kin + emg = 83))\n",
    "\n",
    "            flat_ep_test = [item for sublist in ep_mean_test for item in sublist] # UNIDIMENSIONAL ARRAY: 1 x (number of bins x number of sensors)\n",
    "            test_list.append(flat_ep_test)\n",
    "            test_lab.append(each_test_trial['Given'].iloc[0])\n",
    "            \n",
    "    # REMOVE ROWS WITH NANs\n",
    "    dataframe_train = pd.DataFrame(train_list)\n",
    "    dataframe_train['Given'] = train_lab\n",
    "    dataframe_train_clean = dataframe_train.dropna()\n",
    "    \n",
    "    dataframe_test = pd.DataFrame(test_list)\n",
    "    dataframe_test['Given'] = test_lab\n",
    "    dataframe_test_clean = dataframe_test.dropna()\n",
    "    \n",
    "    # LOGISTIC REGRESSION\n",
    "    log_model = LogisticRegression(penalty='elasticnet', C=C_par, solver='saga', max_iter=25000, multi_class='multinomial', n_jobs=-1, l1_ratio=l1vsl2)\n",
    "    log_model.fit(dataframe_train_clean.drop('Given', axis=1), dataframe_train_clean['Given'])\n",
    "    weights = log_model.coef_\n",
    "    # print(\"Size Weights: \", weights.shape)\n",
    "    # print(\"Classes: \", log_model.classes_)\n",
    "    \n",
    "#     # WRITE WEIGHTS INTO A FILE\n",
    "#     file_name = \"./PyData/KIN_EMG_Norm_weights_N05_\" + family_to_select + \".csv\"\n",
    "#     # weights = log_model.coef_\n",
    "#     resh = weights.reshape((weights.shape[0], int(weights.shape[1]/num_bins), num_bins))\n",
    "#     mean_resh = np.mean(np.abs(resh), axis=2)\n",
    "#     df = pd.DataFrame(mean_resh, index=log_model.classes_)\n",
    "#     df.to_csv(file_name, index=True, header=None, mode='a')\n",
    "#     print(\"FILE UPDATED\")\n",
    "    \n",
    "    # GET PREDICTIONS\n",
    "    pred = log_model.predict_proba(dataframe_test_clean.drop('Given', axis=1))\n",
    "    cl = log_model.classes_\n",
    "    hits = 0\n",
    "    for i in range(len(pred)):\n",
    "        if cl[np.argmax(pred[i])] == dataframe_test_clean.iloc[i]['Given']:\n",
    "            hits += 1\n",
    "    acc = round((hits/dataframe_test_clean.shape[0])*100, 2)\n",
    "    total_acc.append(acc)\n",
    "    print(\"Hits: \", hits, \" out of \", dataframe_test_clean.shape[0], \". \", acc, \"%\")\n",
    "\n",
    "print(\"|| FAMILY: \", family_to_select, \" || Mean accuracy after \", cv, \" folds with \", num_bins, \" bins per EP: \", round(np.mean(total_acc), 2), \" % ||\")\n",
    "print(\"DONE!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed57e66d-a57c-4870-9b31-a49bc2604fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4407b0f4-2461-4e01-ab50-9b2edc665826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
